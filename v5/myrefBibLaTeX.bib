@inproceedings{teixeiraEnhancingCreditRisk2023,
	location = {New York, {NY}, {USA}},
	title = {Enhancing Credit Risk Reports Generation using {LLMs}: An Integration of Bayesian Networks and Labeled Guide Prompting},
	isbn = {979-8-4007-0240-2},
	url = {https://dl.acm.org/doi/10.1145/3604237.3626902},
	doi = {10.1145/3604237.3626902},
	series = {{ICAIF} '23},
	shorttitle = {Enhancing Credit Risk Reports Generation using {LLMs}},
	abstract = {Credit risk analysis is a process that involves a wide range of complex cognitive abilities. Automating the credit risk analysis process using Large Language Models can bring transformative changes to the finance industry, but not without appropriate measures to ensure trustworthy responses. In this work, we propose a novel prompt-engineering method that enhances the ability of Large Language Models to generate reliable credit risk reports - Labeled Guide Prompting ({LGP}). {LGP} consists of: (1) providing annotated few-shot examples to the {LLM} that denote sets of tokens in an exemplary prompt that are of greater importance when generating sets of tokens in the exemplary response and (2) providing text in the prompt that describes the direction, pathways and interactions between variables from a Bayesian network used for credit risk assessment, thus promoting abductive reasoning. Using data from 100 credit applications, we demonstrate that {LGP} enables {LLMs} to generate credit risk reports that are preferred by human credit analysts (in 60-90\% of cases) over alternative credit risk reports created by their peers in a blind review. Additionally, we found a statistically significant improvement (p-value \&lt; 10âˆ’ 10) in the insightfulness of the responses generated using {LGP} when compared to identical prompts without {LGP} components. We conclude that Labeled Guide Prompting can enhance {LLM} performance in complex problem-solving tasks, achieving a level of competency comparable to or exceeding human experts.},
	pages = {340--348},
	booktitle = {Proceedings of the Fourth {ACM} International Conference on {AI} in Finance},
	publisher = {Association for Computing Machinery},
	author = {Teixeira, Ana Clara and Marar, Vaishali and Yazdanpanah, Hamed and Pezente, Aline and Ghassemi, Mohammad},
	urldate = {2024-12-19},
	date = {2023-11-25},
	file = {Full Text PDF:/home/j/snap/zotero-snap/common/Zotero/storage/AC3XMSIW/Teixeira et al. - 2023 - Enhancing Credit Risk Reports Generation using LLMs An Integration of Bayesian Networks and Labeled.pdf:application/pdf},
}

@misc{sanz-guerreroCreditRiskMeets2024,
	title = {Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending},
	url = {http://arxiv.org/abs/2401.16458},
	doi = {10.48550/arXiv.2401.16458},
	shorttitle = {Credit Risk Meets Large Language Models},
	abstract = {Peer-to-peer (P2P) lending has emerged as a distinctive financing mechanism, linking borrowers with lenders through online platforms. However, P2P lending faces the challenge of information asymmetry, as lenders often lack sufficient data to assess the creditworthiness of borrowers. This paper proposes a novel approach to address this issue by leveraging the textual descriptions provided by borrowers during the loan application process. Our methodology involves processing these textual descriptions using a Large Language Model ({LLM}), a powerful tool capable of discerning patterns and semantics within the text. Transfer learning is applied to adapt the {LLM} to the specific task at hand. Our results derived from the analysis of the Lending Club dataset show that the risk score generated by {BERT}, a widely used {LLM}, significantly improves the performance of credit risk classifiers. However, the inherent opacity of {LLM}-based systems, coupled with uncertainties about potential biases, underscores critical considerations for regulatory frameworks and engenders trust-related concerns among end-users, opening new avenues for future research in the dynamic landscape of P2P lending and artificial intelligence.},
	number = {{arXiv}:2401.16458},
	publisher = {{arXiv}},
	author = {Sanz-Guerrero, Mario and Arroyo, Javier},
	urldate = {2024-12-19},
	date = {2024-08-05},
	eprinttype = {arxiv},
	eprint = {2401.16458 [q-fin]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Quantitative Finance - Risk Management},
	file = {Preprint PDF:/home/j/snap/zotero-snap/common/Zotero/storage/RVTCUSIR/Sanz-Guerrero and Arroyo - 2024 - Credit Risk Meets Large Language Models Building a Risk Indicator from Loan Descriptions in P2P Len.pdf:application/pdf;Snapshot:/home/j/snap/zotero-snap/common/Zotero/storage/HKPGIUKZ/2401.html:text/html},
}

@misc{khojaAIBondValues2024,
	location = {Rochester, {NY}},
	title = {{AI} and Bond Values: How Large Language Models Predict Default Signals},
	url = {https://papers.ssrn.com/abstract=4965227},
	doi = {10.2139/ssrn.4965227},
	shorttitle = {{AI} and Bond Values},
	abstract = {This paper investigates the potential of Large Language Models ({LLMs}) to interpret textual data from company earnings calls and assess default likelihood. Using {ChatGPT} to analyze earnings call transcripts, I find that {LLM}-derived default likelihoods enhance the predictability of corporate bond credit spreads, independent of stock prices and liquidity measures. By comparing actual credit spreads with counterfactual spreads predicted using {LLM}-based default likelihoods, I show that {LLMs} reduce serial correlation in credit spreads, indicating less under-reaction to information. This research highlights {LLMs}' role in improving market efficiency by providing a consistent method for processing textual data.},
	number = {4965227},
	publisher = {Social Science Research Network},
	author = {Khoja, Moazzam},
	urldate = {2024-12-19},
	date = {2024-09-20},
	langid = {english},
	keywords = {{AI} and Bond Values: How Large Language Models Predict Default Signals, Moazzam Khoja, {SSRN}},
	file = {Full Text PDF:/home/j/snap/zotero-snap/common/Zotero/storage/P7MRCR7U/Khoja - 2024 - AI and Bond Values How Large Language Models Predict Default Signals.pdf:application/pdf},
}

@article{babaeiGPTClassificationsApplication2024,
	title = {{GPT} classifications, with application to credit lending},
	volume = {16},
	issn = {2666-8270},
	url = {https://www.sciencedirect.com/science/article/pii/S2666827024000100},
	doi = {10.1016/j.mlwa.2024.100534},
	abstract = {Generative Pre-trained Transformers ({GPT}) and Large language models ({LLMs}) have made significant advancements in natural language processing in recent years. The practical applications of {LLMs} are undeniable, rendering moot any debate about their impending influence. The power of {LLMs} has made them similar to machine learning models for decision-making problems. In this paper, we focus on binary classification which is a common use of {ML} models, particularly in credit lending applications. We show how a {GPT} model can perform almost as accurately as a classical logistic machine learning model but with a much lower number of sample observations. In particular, we show how, in the context of credit lending, {LLMs} can be improved and reach performances similar to classical logistic regression models using only a small set of examples.},
	pages = {100534},
	journaltitle = {Machine Learning with Applications},
	shortjournal = {Machine Learning with Applications},
	author = {Babaei, Golnoosh and Giudici, Paolo},
	urldate = {2024-12-19},
	date = {2024-06-01},
	keywords = {Artificial intelligence, Credit decisions, Large language models},
}

@misc{fazlijaImplementingFinancialRegulations2024,
	location = {Rochester, {NY}},
	title = {Implementing Financial Regulations Using Large Language Models},
	url = {https://papers.ssrn.com/abstract=5010694},
	abstract = {To strengthen financial stability, regulators worldwide have expanded regulatory requirements, impacting the profitability of financial institutions due to stricter capital requirements and significantly increasing the costs for regulatory implementation projects and ongoing maintenance. Regulatory implementation projects are highly complex due to the need for forming teams with expert knowledge on the new regulation, developing new software for reporting and compliance monitoring, and establishing new databases to support these initiatives. Recent advancements in generative artificial intelligence ({GenAI}), particularly large language models ({LLMs}), are expected to reduce the burden on institutions in these complex implementations, particularly in software development. This paper introduces a Basel {III}-based dataset along with over 6,000 test cases derived from articles of the credit risk standard approach, enabling {LLM}-driven benchmarking for text-to-code capabilities in interpreting regulatory texts. Furthermore, we use state-of-the-art {LLMs} and advanced prompting techniques to enhance code generation and present effective prompt templates for zero-shot learning. To evaluate the code generation capabilities of the {LLMs}, we generate multiple codes using various {LLMs}, temperature settings, and in-context learning techniques. The generated codes are evaluated on the test cases, using an unbiased pass@k proxy-a measure for assessing code generation performance-achieving pass@1 rates of up to 75.38\% and pass@10 rates of up to 91.67\%. These results indicate the proposed methods can significantly support software development for regulatory implementation.},
	number = {5010694},
	publisher = {Social Science Research Network},
	author = {Fazlija, Bledar and Ibraimi, Meriton and Forouzandeh, Aynaz and Fazlija, Arber},
	urldate = {2024-12-19},
	date = {2024-11-05},
	langid = {english},
	keywords = {Artificial Intelligence, Basel {III}, Code Generation, Compliance, Financial Regulation, Generative {AI}, Large Language Models, Machine Learning},
	file = {Full Text PDF:/home/j/snap/zotero-snap/common/Zotero/storage/H7I5ZJG3/Fazlija et al. - 2024 - Implementing Financial Regulations Using Large Language Models.pdf:application/pdf},
}

@misc{ludwigLargeLanguageModels2024,
	title = {Large Language Models: An Applied Econometric Framework},
	url = {http://arxiv.org/abs/2412.07031},
	doi = {10.48550/arXiv.2412.07031},
	shorttitle = {Large Language Models},
	abstract = {Large language models ({LLMs}) are being used in economics research to form predictions, label text, simulate human responses, generate hypotheses, and even produce data for times and places where such data don't exist. While these uses are creative, are they valid? When can we abstract away from the inner workings of an {LLM} and simply rely on their outputs? We develop an econometric framework to answer this question. Our framework distinguishes between two types of empirical tasks. Using {LLM} outputs for prediction problems (including hypothesis generation) is valid under one condition: no "leakage" between the {LLM}'s training dataset and the researcher's sample. Using {LLM} outputs for estimation problems to automate the measurement of some economic concept (expressed by some text or from human subjects) requires an additional assumption: {LLM} outputs must be as good as the gold standard measurements they replace. Otherwise estimates can be biased, even if {LLM} outputs are highly accurate but not perfectly so. We document the extent to which these conditions are violated and the implications for research findings in illustrative applications to finance and political economy. We also provide guidance to empirical researchers. The only way to ensure no training leakage is to use open-source {LLMs} with documented training data and published weights. The only way to deal with {LLM} measurement error is to collect validation data and model the error structure. A corollary is that if such conditions can't be met for a candidate {LLM} application, our strong advice is: don't.},
	number = {{arXiv}:2412.07031},
	publisher = {{arXiv}},
	author = {Ludwig, Jens and Mullainathan, Sendhil and Rambachan, Ashesh},
	urldate = {2024-12-19},
	date = {2024-12-09},
	eprinttype = {arxiv},
	eprint = {2412.07031 [econ]},
	keywords = {Computer Science - Artificial Intelligence, Economics - Econometrics},
	file = {Preprint PDF:/home/j/snap/zotero-snap/common/Zotero/storage/D74TWZFK/Ludwig et al. - 2024 - Large Language Models An Applied Econometric Framework.pdf:application/pdf;Snapshot:/home/j/snap/zotero-snap/common/Zotero/storage/JBRCAPH7/2412.html:text/html},
}

@inproceedings{liEconAgentLargeLanguage2024,
	location = {Bangkok, Thailand},
	title = {{EconAgent}: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities},
	url = {https://aclanthology.org/2024.acl-long.829},
	doi = {10.18653/v1/2024.acl-long.829},
	shorttitle = {{EconAgent}},
	abstract = {The advent of artificial intelligence has led to a growing emphasis on data-driven modeling in macroeconomics, with agent-based modeling ({ABM}) emerging as a prominent bottom-up simulation paradigm. In {ABM}, agents (*e.g.*, households, firms) interact within a macroeconomic environment, collectively generating market dynamics. Existing agent modeling typically employs predetermined rules or learning-based neural networks for decision-making. However, customizing each agent presents significant challenges, complicating the modeling of agent heterogeneity. Additionally, the influence of multi-period market dynamics and multifaceted macroeconomic factors are often overlooked in decision-making processes.In this work, we introduce **{EconAgent}**, a large language model-empowered agent with human-like characteristics for macroeconomic simulation. We first construct a simulation environment that incorporates various market dynamics driven by agents' decisions regarding work and consumption. Through the perception module, we create heterogeneous agents with distinct decision-making mechanisms. Furthermore, we model the impact of macroeconomic trends using a memory module, which allows agents to reflect on past individual experiences and market dynamics.Simulation experiments show that {EconAgent} can make realistic decisions, leading to more reasonable macroeconomic phenomena compared to existing rule-based or learning-based agents. Our codes are released at https://github.com/tsinghua-fib-lab/{ACL}24-{EconAgent}.},
	eventtitle = {{ACL} 2024},
	pages = {15523--15536},
	booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Li, Nian and Gao, Chen and Li, Mingyu and Li, Yong and Liao, Qingmin},
	editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
	urldate = {2024-12-19},
	date = {2024-08},
	file = {Full Text PDF:/home/j/snap/zotero-snap/common/Zotero/storage/36PK5HQ8/Li et al. - 2024 - EconAgent Large Language Model-Empowered Agents for Simulating Macroeconomic Activities.pdf:application/pdf},
}

@misc{liLargeLanguageModelEmpowered2023,
	location = {Rochester, {NY}},
	title = {Large Language Model-Empowered Agents for Simulating Macroeconomic Activities},
	url = {https://papers.ssrn.com/abstract=4606937},
	doi = {10.2139/ssrn.4606937},
	abstract = {The advent of the Web has brought about a paradigm shift in traditional economics, particularly in the digital economy era, enabling the precise recording and analysis of individual economic behavior. This has led to a growing emphasis on data-driven modeling in macroeconomics. In macroeconomic research,  Agent-based modeling ({ABM}) emerged as an alternative, evolving through rule-based agents, machine learning-enhanced decision-making, and, more recently, advanced {AI} agents. However, the existing works are suffering from three main challenges when endowing agents with human-like decision-making, including agent heterogeneity, the influence of macroeconomic trends, and multifaceted economic factors. Large language models ({LLMs}) have recently gained prominence in offering autonomous human-like characteristics. Therefore, leveraging {LLMs} in macroeconomic simulation presents an opportunity to overcome traditional limitations. In this work, we take an early step in introducing a novel approach that leverages {LLMs} in macroeconomic simulation. We design prompt-engineering-driven {LLM} agents to exhibit human-like decision-making and adaptability in the economic environment, with the abilities of perception, reflection, and decision-making to address the abovementioned challenges. Simulation experiments on macroeconomic activities show that {LLM}-empowered agents can make realistic work and consumption decisions and emerge more reasonable macroeconomic phenomena than existing rule-based or {AI} agents. Our work demonstrates the promising potential to simulate macroeconomics based on {LLM} and its human-like characteristics.},
	number = {4606937},
	publisher = {Social Science Research Network},
	author = {Li, Nian and Gao, Chen and Li, Yong and Liao, Qingmin},
	urldate = {2024-12-19},
	date = {2023-10-13},
	langid = {english},
	keywords = {Large Language Models, Economic Simulation, Web and Economics},
	file = {Full Text PDF:/home/j/snap/zotero-snap/common/Zotero/storage/5MKXDSLJ/Li et al. - 2023 - Large Language Model-Empowered Agents for Simulating Macroeconomic Activities.pdf:application/pdf},
}

@inproceedings{nascimentoGPTDataScience2023,
	title = {{GPT} in Data Science: A Practical Exploration of Model Selection},
	url = {https://ieeexplore.ieee.org/abstract/document/10386503},
	doi = {10.1109/BigData59044.2023.10386503},
	shorttitle = {{GPT} in Data Science},
	abstract = {There is an increasing interest in leveraging Large Language Models ({LLMs}) for managing structured data and enhancing data science processes. Despite the potential benefits, this integration poses significant questions regarding their reliability and decision-making methodologies. Our objective is to elucidate and express the factors and assumptions guiding {GPT}-4â€™s model selection recommendations. It highlights the importance of various factors in the model selection process, including the nature of the data, problem type, performance metrics, computational resources, interpretability vs accuracy, assumptions about data, and ethical considerations. We employ a variability model to depict these factors and use toy datasets to evaluate both the model and the implementation of the identified heuristics. By contrasting these outcomes with heuristics from other platforms, our aim is to determine the effectiveness and distinctiveness of {GPT}-4â€™s methodology. This research is committed to advancing our comprehension of {AI} decision-making processes, especially in the realm of model selection within data science. Our efforts are directed towards creating {AI} systems that are more transparent and comprehensible, contributing to a more responsible and efficient practice in data science.},
	eventtitle = {2023 {IEEE} International Conference on Big Data ({BigData})},
	pages = {4325--4334},
	booktitle = {2023 {IEEE} International Conference on Big Data ({BigData})},
	author = {Nascimento, Nathalia and Tavares, Cristina and Alencar, Paulo and Cowan, Donald},
	urldate = {2024-12-19},
	date = {2023-12},
	keywords = {Analytical models, Computational modeling, Data science, Data Science, Decision making, Generative Pre-trained Transformer ({GPT}), Heuristic Analysis, Machine Learning Model Selection, Measurement, Toy manufacturing industry, Transformers, Variability Model},
	file = {IEEE Xplore Abstract Record:/home/j/snap/zotero-snap/common/Zotero/storage/AZVIDN82/10386503.html:text/html;Submitted Version:/home/j/snap/zotero-snap/common/Zotero/storage/4MQHWU73/Nascimento et al. - 2023 - GPT in Data Science A Practical Exploration of Model Selection.pdf:application/pdf},
}
